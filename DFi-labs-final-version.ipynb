{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Preparation and Exploratory Analysis**\n",
                "\n",
                "Load libraries:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "rm(list = ls())\n",
                "\n",
                "#These if statements used in case libraries are not installed on someone else's environment\n",
                "if (!require(tidyverse)) install.packages('tidyverse')\n",
                "if (!require(xts)) install.packages('xts')\n",
                "if (!require(caret)) install.packages('caret')\n",
                "if (!require(kernlab)) install.packages('kernlab')\n",
                "if (!require(roll)) install.packages('roll')\n",
                "if (!require(Rcpp)) install.packages('Rcpp')\n",
                "if (!require(skimr)) install.packages('skimr')\n",
                "if (!require(h2o)) install.packages('h2o')\n",
                "\n",
                "library(tidyverse)\n",
                "library(xts)\n",
                "library(caret)\n",
                "library(kernlab)\n",
                "library(roll)\n",
                "library(Rcpp)\n",
                "library(skimr)\n",
                "library(h2o)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Change path to the data on your computer:\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#data <- read.csv(\"C:/Users/d/Downloads/dfi_labs_BTCUSDT-1h-spot-data.csv\")\n",
                "\n",
                "\n",
                "data <- read.csv(\"/Users/nikhil/Downloads/dfi_labs_BTCUSDT-1h-spot-data.csv\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Data preparation:\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data$Start <- strptime(data$Start_time, format = \"%M/%d/%Y %H:%M\")\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Volatility calculation:\n",
                "\n",
                "Volatility was defined as the standard deviation of the opening prices for the previous 24 hours of a given trading window. I thought about using an API to pull the data for 05/31 but I didn't know which exchange was used in the rest of the data, and they are all a little different. I ended up deciding to take the standard deviation of the opening prices on 6/1 and make that the volatility value for the first 24 hours.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#calculate rolling SD\n",
                "volatility_rest <- roll_sd(data$Open, width = 24)\n",
                "\n",
                "#remove the first 24 values\n",
                "volatility_rest <- roll_sd(data$Open, width = 24)[24:5575]\n",
                "\n",
                "#calculate SD of BTC price for 1st trading day\n",
                "for_now <- sd(data$Open[1:24])\n",
                "\n",
                "#since we don't have data before, use the first day's SD as the rolling SD for the first day\n",
                "vec_holder <- rep(for_now, 24)\n",
                "\n",
                "#add vectors together\n",
                "volatility <- c(vec_holder, volatility_rest)\n",
                "\n",
                "#create a new column in the DF to represent volatilty (sigma/rolling standard deviation of previous 24 hours BTC opening price)\n",
                "data$volatility <- volatility\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "Stop loss/Take Profit Price calculations (using 2*sigma formula):\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#calculate take profit and stop loss price for each trading interval as Open +/- 2*sigma\n",
                "data$take_profit <- data$Open + 2*data$volatility\n",
                "data$stop_loss <- data$Open - 2*data$volatility\n",
                "\n",
                "#create columns to indicate if BTC price hit stop/take profit price/remained in band within each interval\n",
                "data$hit_stop <- ifelse(data$Low <= data$stop_loss, 1, 0)\n",
                "data$hit_take_profit <- ifelse(data$High >= data$take_profit, 1, 0)\n",
                "data$within_band <- ifelse(data$hit_stop == 0 & data$hit_take_profit == 0, 1, 0)\n",
                "\n",
                "#there were 4 intervals where BTC price hit both stop and take profit, this column indicates this\n",
                "data$hit_both_stop_and_profit <- ifelse(data$hit_stop == 1 & data$hit_take_profit == 1, 1, 0)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Calculate and visualize how many observations in the data set fall into each category. I added a fourth category because I noticed that there were some instances where the price hit both the stop loss and the take profit price.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Use the above columns to determine which of 4 categories each trading interval corresponded to. This will be the outcome variable once we start modeling.\n",
                "data$category[data$hit_stop == 1 & data$hit_both_stop_and_profit == 0] <- \"HIT_STOP\"\n",
                "data$category[data$hit_take_profit == 1 & data$hit_both_stop_and_profit == 0] <- \"TAKE_PROFIT\"\n",
                "data$category[data$within_band == 1 & data$hit_both_stop_and_profit == 0] <- \"WITHIN_BAND\"\n",
                "data$category[data$hit_stop == 1 & data$hit_both_stop_and_profit == 1] <- \"HIT_BOTH\"\n",
                "\n",
                "\n",
                "#calculate column totals\n",
                "tmp_vec <- sapply(data[14:17], sum)\n",
                "\n",
                "#use column sums to figure out how many in each category, subtract out non mutually exclusive events\n",
                "num_hit_both <- as.integer(tmp_vec[4])\n",
                "num_hit_stop <- as.integer(tmp_vec[1]) - num_hit_both\n",
                "num_hit_TP <- as.integer(tmp_vec[2]) - num_hit_both\n",
                "num_within_band <- as.integer(tmp_vec[3])\n",
                "total_observations <- count(data)$n\n",
                "\n",
                "#turn into a df to graph with ggplot\n",
                "tmp <- data.frame(\n",
                "  \"categories\" <- c(\"hit_both\", \"hit_stop\", \"hit_TP\", \"stayed_in_band\", \"total_observations\"),\n",
                "  \"values\" <- c(num_hit_both, num_hit_stop, num_hit_TP, num_within_band, total_observations)\n",
                ")\n",
                "colnames(tmp) <- c(\"category\", \"value\")\n",
                "\n",
                "\n",
                "ggplot(data = tmp[1:4,], aes(x = category, y =value, fill = category)) + \n",
                "  geom_bar(stat = \"identity\") + \n",
                "  geom_text(aes(label=value), position=position_dodge(width=0.9), vjust=-0.25) +\n",
                "  ggtitle(\"Number of Data Points by Category\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This column can be used to calculate the total profit that would be made using a hypothetical trading algorithm. The column value corresponds to the total difference in price between the entry and exit price of each trading window, based on the value of the \"category column\". To find the actual profit, create a new column that represents this column plus the amount of USD traded in a given trading window, then sum the column. This wasn't given so I did not calculate the actual number.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data$profit <- NA\n",
                "\n",
                "#Once we know how much is being traded per trading window, to find the actual number multiply below by the volume of BTC traded. Below is only calculating the difference in trade entry/exit prices.\n",
                "for(i in 1:length(data$Open)){\n",
                "  \n",
                "  #If hits both stop and TP price, then consider the exit price of the trade to be avg of TP/Stop since you don't know which happened first\n",
                "  if(data$category[i] == \"HIT_BOTH\"){\n",
                "    data$profit[i] <- data$Open[i] - mean(data$take_profit[i], data$stop_loss[i])\n",
                "  }else if(data$category[i] == \"HIT_STOP\"){\n",
                "    data$profit[i] <- data$stop_loss[i] - data$Open[i]\n",
                "  }else if(data$category[i] == \"TAKE_PROFIT\"){\n",
                "    data$profit[i] <- data$stop_loss[i] + data$Open[i]\n",
                "  }else{ #This is the within_band category but you don't need to specify because its the last option\n",
                "   data$profit[i] <- data$Close[i] - data$Open[i] \n",
                "  }\n",
                "}\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Quick pairs plot to identify any obvious correlations between variables:  \n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tmp <- select(data, category, qav, Open, volatility, profit)\n",
                "pairs(tmp[2:5])\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "Generate summary stats of all variables in the data frame:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "skim(data)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now lets prepare to make some models to predict which category the BTC price will fall into:\n",
                "\n",
                "**Modeling**\n",
                "\n",
                "Use an 80/20 split to split the data into testing and training sets to avoid model overfitting: \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "a <- createDataPartition(data$category, p = 0.8, list=FALSE)\n",
                "training <- data[a,]\n",
                "test <- data[-a,]\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Fit a simple Linear Discriminant Analysis (LDA) model, evaluate what proportion of cases are predicted correctly:\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#fit model\n",
                "lda <- train(category ~ qav + Open + volatility, \n",
                "                data = training, \n",
                "                method=\"lda\")\n",
                "#Generate predictions\n",
                "test$predicted_category <- predict(lda, newdata = test)\n",
                "\n",
                "num_test_observations <- count(test)$n\n",
                "\n",
                "#Calculate the number of correct predictions\n",
                "#make a binary column to represent if the prediction was correct.\n",
                "test$predicted_correct <- ifelse(test$category == test$predicted_category, 1, 0)\n",
                "\n",
                "num_correct_predictions <- sum(test$predicted_correct)\n",
                "lda_test_prop_predicted_correctly <- num_correct_predictions/num_test_observations\n",
                "\n",
                "lda_test_prop_predicted_correctly\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Fit a Support Vector Machines (SVM) model: \n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Set up Repeated k-fold Cross Validation\n",
                "train_control <- trainControl(method=\"cv\", number=10)\n",
                "\n",
                "# Fit the model \n",
                "svm1 <- train(category ~ Open + volatility, data = data, method = \"svmLinear\", trControl = train_control)\n",
                "#View the model\n",
                "svm1\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Make predictions using the SVM model:\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#on full data\n",
                "data$predicted_category <- predict(svm1, newdata = data)\n",
                "\n",
                "#Calculate the number of correct predictions\n",
                "#make a binary column to represent if the prediction was correct.\n",
                "data$predicted_correct <- ifelse(data$category == data$predicted_category, 1, 0)\n",
                "\n",
                "num_correct_predictions <- sum(data$predicted_correct)\n",
                "full_data_prop_predicted_correctly <- num_correct_predictions/total_observations\n",
                "\n",
                "full_data_prop_predicted_correctly\n",
                "\n",
                "#on test\n",
                "test$predicted_category <- predict(svm1, newdata = test)\n",
                "\n",
                "#Calculate the number of correct predictions\n",
                "#make a binary column to represent if the prediction was correct.\n",
                "test$predicted_correct <- ifelse(test$category == test$predicted_category, 1, 0)\n",
                "\n",
                "test_num_correct_predictions <- sum(test$predicted_correct)\n",
                "svm_1_test_prop_predicted_correctly <- test_num_correct_predictions/num_test_observations\n",
                "\n",
                "svm_1_test_prop_predicted_correctly\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Add more variables with lag**\n",
                "\n",
                "The previous models did not include qav or profit as variables. That is because qav and profit are both metrics that require information that is only obtained at the end of a trading window, and thus cannot be used to predict. I wanted to include these variables in the model, so I used a lag function to make the value of the qav and profit variables equal to their values in the previous trading window.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#use indexing to shift the value of qav and profit down by one row\n",
                "lagged_qav <- data$qav[1:5575]\n",
                "lagged_profit <- data$profit[1:5575]\n",
                "lagged_dataset <- data\n",
                "lagged_dataset$qav[1] <- NA\n",
                "lagged_dataset$profit[1] <- NA\n",
                "lagged_dataset$qav[2:5576] <- lagged_qav\n",
                "lagged_dataset$profit[2:5576] <- lagged_qav\n",
                "\n",
                "#remove the first row of the dataset so that way NA value doesn't throw errors when fitting model\n",
                "lagged_dataset <- lagged_dataset[2:5576,]\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "SVM using Open + Volatility + qav:\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Set up Repeated k-fold Cross Validation\n",
                "train_control <- trainControl(method=\"cv\", number=5)\n",
                "\n",
                "svm2 <- train(category ~ Open + volatility + qav, \n",
                "              data = lagged_dataset, method = \"svmLinear\", \n",
                "              trControl = train_control)\n",
                "\n",
                "#View the model\n",
                "svm2\n",
                "\n",
                "\n",
                "#on test\n",
                "test_observations <- count(test)$n\n",
                "test$predicted_category <- predict(svm2, newdata = test)\n",
                "\n",
                "#Calculate the number of correct predictions\n",
                "#make a binary column to represent if the prediction was correct.\n",
                "test$predicted_correct <- ifelse(test$category == test$predicted_category, 1, 0)\n",
                "\n",
                "test_num_correct_predictions <- sum(test$predicted_correct)\n",
                "svm_2_test_prop_predicted_correctly <- test_num_correct_predictions/test_observations\n",
                "\n",
                "svm_2_test_prop_predicted_correctly\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "SVM using Open + Volatility + lagged qav + lagged profit:\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Set up Repeated k-fold Cross Validation\n",
                "train_control <- trainControl(method=\"cv\", number=5)\n",
                "\n",
                "svm3 <- train(category ~ Open + volatility + qav + profit, \n",
                "              data = lagged_dataset, method = \"svmLinear\", \n",
                "              trControl = train_control)\n",
                "\n",
                "#View the model\n",
                "svm3\n",
                "data$svm_predicted_category <- predict(svm3, newdata = data)\n",
                "\n",
                "\n",
                "#on test\n",
                "test_observations <- count(test)$n\n",
                "test$predicted_category <- predict(svm3, newdata = test)\n",
                "\n",
                "#Calculate the number of correct predictions\n",
                "#make a binary column to represent if the prediction was correct.\n",
                "test$predicted_correct <- ifelse(test$category == test$predicted_category, 1, 0)\n",
                "\n",
                "test_num_correct_predictions <- sum(test$predicted_correct)\n",
                "svm_3_test_prop_predicted_correctly <- test_num_correct_predictions/test_observations\n",
                "\n",
                "svm_3_test_prop_predicted_correctly\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Build a model using h2o auto ML library:\n",
                "\n",
                "\n",
                "Initiate auto ML and fit model:\n",
                "\n",
                "**Be mindful that this chunk will take approximately 10 minutes to run:**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "knitr::opts_chunk$set(cache = TRUE)\n",
                "\n",
                "h2o.init()\n",
                "h2o.no_progress()\n",
                "\n",
                "lagged_dataset$category <- as.factor(lagged_dataset$category)\n",
                "\n",
                "h20.data <- as.h2o(lagged_dataset[,c(2,9,11, 18, 19)])\n",
                "\n",
                "auto_ml_test <- as.h2o(select(test, Open, qav, volatility, profit), use_datatable = TRUE)\n",
                "\n",
                "auto_ml_full <- as.h2o(select(data, Open, qav, volatility, profit), use_datatable = TRUE)\n",
                "\n",
                "aml <- h2o.automl(x = c(\"Open\", \"qav\", \"volatility\", \"profit\"),\n",
                "                  y = \"category\",\n",
                "                  training_frame = h20.data,\n",
                "                  max_runtime_secs = 500)\n",
                "\n",
                "aml@leaderboard\n",
                "h2o.performance(aml@leader)\n",
                "\n",
                "#save best model\n",
                "best_model <- h2o.get_best_model(aml, \"any\")\n",
                "\n",
                "#display best autoML model\n",
                "#aml@leader\n",
                "#aml@leader@allparameters\n",
                "\n",
                "#obtain the predictions\n",
                "h2o_preds <- predict(best_model, newdata = auto_ml_test)\n",
                "h2o_preds_df <- as.data.frame(h2o_preds)\n",
                "\n",
                "h2o_preds_full <- predict(best_model, newdata = auto_ml_full)\n",
                "h2o_preds_df_full <- as.data.frame(h2o_preds_full)\n",
                "\n",
                "data$auto_ml_predicted_category <- NA\n",
                "data$auto_ml_predicted_category <- h2o_preds_df_full$predict\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "Calculate prediction error:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "test_observations <- count(test)$n\n",
                "\n",
                "test$auto_ml_prediction <- h2o_preds_df$predict\n",
                "\n",
                "#Calculate the number of correct predictions\n",
                "#make a binary column to represent if the prediction was correct.\n",
                "test$auto_ml_predicted_correct <- ifelse(test$category == test$auto_ml_prediction, 1, 0)\n",
                "\n",
                "num_correct_predictions <- sum(test$auto_ml_predicted_correct)\n",
                "auto_ml_prop_predicted_correctly <- num_correct_predictions/test_observations\n",
                "\n",
                "auto_ml_prop_predicted_correctly\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Bar graph of prediction accuracies by model:\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#create a df to hold model names and pred accuracies\n",
                "model_names <- c(\"lda\",\"svm1\", \"svm2\", \"svm3\", \"Deep Learning (autoML)\")\n",
                "prediction_accuracies <- c(lda_test_prop_predicted_correctly, svm_1_test_prop_predicted_correctly,\n",
                "                           svm_2_test_prop_predicted_correctly, svm_3_test_prop_predicted_correctly,\n",
                "                           auto_ml_prop_predicted_correctly)\n",
                "\n",
                "tmp2 <- data.frame(cbind(model_names, prediction_accuracies))\n",
                "\n",
                "#round pred accuracy to 2 digits to make graph easier to read\n",
                "\n",
                "tmp2$prediction_accuracies <- as.double(tmp2$prediction_accuracies)\n",
                "tmp2$prediction_accuracies <- round(tmp2$prediction_accuracies, digits = 3)\n",
                "\n",
                "ggplot(tmp2, aes(x = model_names, y = prediction_accuracies, fill = prediction_accuracies)) + geom_bar(stat = \"identity\") + \n",
                "  geom_text(aes(label = prediction_accuracies, vjust=0)) +\n",
                "  labs(y = \"Prediction Accuracies\", x = \"Model Name\") +\n",
                "  ggtitle(\"Prediction Accuracy by Model\") + guides(fill=guide_legend(title=\"Prediction Accuracy\"))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The model with the highest prediction accuracy was the SVM3 model (94.2%). Lets backtest the amount of predicted profit and percentage return assuming 0.0027 BTC (equal to 100 USD on 1/30/21) traded per window. I will tell the algorithm to not make trades during intervals where the category predicted was hit_stop. We will also calculate what the \"perfect\" return could be if everything were classified correctly:\n",
                "\n",
                "\n",
                "**Predicted Percent Return by Model**\n",
                "\n",
                "Calculate what the percent return and profit would be in the case of 100% classification accuracy:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "amount_btc_invested <- 0.0027\n",
                "amount_USD_invested <- 100 * total_observations \n",
                "\n",
                "for(i in 1:length(data$category)){\n",
                "  if(data$category[i] == \"HIT_STOP\"){\n",
                "    #if you are predicting it will hit stop then you will just not make the trade, so set the profit to zero\n",
                "    data$profit[i] <- 0\n",
                "  }else if(data$category[i] == \"TAKE_PROFIT\"){\n",
                "    data$profit[i] <- data$take_profit[i] - data$Open[i]\n",
                "  }else if(data$category[i] == \"HIT_BOTH\"){\n",
                "    data$profit[i] <- data$Close[i] - data$Open[i]\n",
                "  }else{ \n",
                "    #corresponds to BTC price staying within band\n",
                "    data$profit[i] <- data$Close[i] - data$Open[i]\n",
                "  }\n",
                "}\n",
                "\n",
                "actual_profit <- sum(data$profit)\n",
                "\n",
                "actual_percent_return <- actual_profit / amount_USD_invested\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "Calculate predicted profit using SV3 model:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#obtain the profit and percent return predictions\n",
                "\n",
                "data$predicted_category <- predict(svm3, data)\n",
                "\n",
                "#since everything was within the using this model band, trades would close at the closing price\n",
                "\n",
                "data$predicted_profit <- data$Close -  data$Open\n",
                "predicted_profit <- sum(data$predicted_profit)\n",
                "\n",
                "svm_percent_return <- predicted_profit / amount_USD_invested\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Calculate percent return using autoML model:\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Using automl\n",
                "\n",
                "data$auto_ml_predicted_profit <- ifelse(data$auto_ml_predicted_category == \"TAKE_PROFIT\",\n",
                "                                        data$take_profit - data$Open, data$Close - data$Open)\n",
                "\n",
                "auto_ml_predicted_profit <- sum(data$auto_ml_predicted_profit)\n",
                "\n",
                "auto_ml_percent_return <-  auto_ml_predicted_profit / amount_USD_invested\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Why I ultimately decided to pick LDA model**\n",
                "\n",
                "Originally, I was going to submit SVM as the best model. SVM and the deep learning model from autoML have higher predictive accuracy than LDA, but they have major shortcomings. They are achieving high classification accuracy by classifying everything as falling within the band, and are giving high rates of error in predicting the other categories. Out of all 5576 observations in the data set, 5246 actually fall within the trading band, which is how SVM is achieving such high classification accuracy. AutoML is a little bit better and correctly predicts 73/172 cases as hitting the stop loss.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "table(data$category)\n",
                "table(data$svm_predicted_category)\n",
                "table(data$auto_ml_predicted_category)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "However, incorrectly predicting hitting the stop loss is a big problem. Approximately half of all trading windows have closing prices lower than opening prices, and when predicting, hitting the stop loss is the only instance in which we can remove instances where profit is lost. This is because we can simply instruct the computer not to make trades where stop losses would be hit. Conversely, when we predict that the take profit price will be hit, this is a way to guarantee profit:\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "hist(data$profit, main = \"Difference Between Closing and Opening Price\", xlab = \"Difference\",\n",
                "     labels = TRUE)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Ultimately, I decided to choose the LDA model as the final model, and tried to use cross validation to improve its final predictive accuracy. I choose 5 folds instead of 10 because I figured that we didn't have a large enough dataset for 10 folds, but using 5 or 10 did not end up changing the predictive accuracy on the test set. \n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_control <- trainControl(method=\"cv\", number=5)\n",
                "\n",
                "lda_cv <- train(category ~ qav + Open + volatility + profit, \n",
                "                data = data, \n",
                "                method=\"lda\",\n",
                "                trControl = train_control)\n",
                "#Generate predictions\n",
                "data$lda_predicted_category <- predict(lda_cv, newdata = data)\n",
                "num_observations <- count(data)$n\n",
                "\n",
                "data$predicted_correct <- ifelse(data$category == data$lda_predicted_category, 1, 0)\n",
                "\n",
                "num_correct_predictions <- sum(data$predicted_correct)\n",
                "lda_prop_predicted_correctly <- num_correct_predictions/num_observations\n",
                "\n",
                "lda_prop_predicted_correctly\n",
                "\n",
                "\n",
                "#calculate test set error\n",
                "#Generate predictions\n",
                "test$predicted_category <- predict(lda_cv, newdata = test)\n",
                "\n",
                "num_test_observations <- count(test)$n\n",
                "\n",
                "#Calculate the number of correct predictions\n",
                "#make a binary column to represent if the prediction was correct.\n",
                "test$predicted_correct <- ifelse(test$category == test$predicted_category, 1, 0)\n",
                "\n",
                "num_correct_predictions <- sum(test$predicted_correct)\n",
                "lda_cv_test_prop_predicted_correctly <- num_correct_predictions/num_test_observations\n",
                "\n",
                "lda_cv_test_prop_predicted_correctly\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Cross validation improved LDA predictve accuracy on the test set from 0.9478886 to 0.9667565:\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Predictive accuracy test/train split: \")\n",
                "lda_test_prop_predicted_correctly\n",
                "\n",
                "print(\"Predictive accuracy with 5 fold cv: \")\n",
                "lda_cv_test_prop_predicted_correctly\n",
                "\n",
                "table(data$lda_predicted_category)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We see that LDA predicted that 81 rows would be in the stop loss category. Allowing all these trades to be cancelled will save us lots of money. I will calculate the predicted percent return and profit of the LDA model below:\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#predict profit using LDA\n",
                "\n",
                "data$lda_predicted_profit <- NA\n",
                "\n",
                "for(i in 1:length(data$lda_predicted_category)){\n",
                "  if(data$lda_predicted_category[i] == \"HIT_STOP\"){\n",
                "    #if you are predicting it will hit stop then you will just not make the trade, so set the profit to zero\n",
                "    data$lda_predicted_profit[i] <- 0\n",
                "  }else if(data$lda_predicted_category[i] == \"TAKE_PROFIT\"){\n",
                "    data$lda_predicted_profit[i] <- data$take_profit[i] - data$Open[i]\n",
                "  }else if(data$lda_predicted_category[i] == \"HIT_BOTH\"){\n",
                "    data$lda_predicted_profit[i] <- data$Close[i] - data$Open[i]\n",
                "  }else{ \n",
                "    #corresponds to BTC price staying within band\n",
                "    data$lda_predicted_profit[i] <- data$Close[i] - data$Open[i]\n",
                "  }\n",
                "}\n",
                "\n",
                "lda_predicted_profit <- sum(data$lda_predicted_profit)\n",
                "\n",
                "lda_percent_return <- lda_predicted_profit / amount_USD_invested\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "To conclude, the best model actually turned out to be LDA. Initially I ingored this model, but once I used cross validation to fit it, it turned out to have the highest prediction accuracy and the closest percent return to what the best possible percent return could have been with 100% predictive accuracy:\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "models <- c(\"SVM\", \"Deep Learning\", \"LDA\", \"Actual Data\")\n",
                "pct_return <- c(svm_percent_return, auto_ml_percent_return, lda_percent_return, actual_percent_return)\n",
                "\n",
                "tmp3 <- data.frame(cbind(models, pct_return))\n",
                "tmp3$pct_return <- as.double(tmp3$pct_return)\n",
                "tmp3$pct_return <- round(tmp3$pct_return, digits = 2)\n",
                "\n",
                "ggplot(tmp3, aes(x = models, y = pct_return, fill = models)) +\n",
                "  geom_bar(stat = \"identity\") + geom_text(aes(label = pct_return, vjust=0)) + \n",
                "  ggtitle(\"Predicted Percentage Return by Model\") + \n",
                "  labs(y = \"Percentage Return\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "To further improve on this method, I would suggest not classifying into categories. Using classification is less helpful for this specific dataset as 94% of the values will fall within the volatility band, meaning you would exit the trade at the closing price. Since approximately half of the time the closing price is lower than the opening, this means we would be losing money on approximately half of the trades. Maybe through predicting a continuous value like the BTC price we would be able to avoid losing money on a higher proportion of trades. This is not guaranteed to work, but rather an idea I had for improving our return. \n"
            ]
        }
    ],
    "metadata": {
        "anaconda-cloud": "",
        "kernelspec": {
            "display_name": "R",
            "langauge": "R",
            "name": "ir"
        },
        "language_info": {
            "codemirror_mode": "r",
            "file_extension": ".r",
            "mimetype": "text/x-r-source",
            "name": "R",
            "pygments_lexer": "r",
            "version": "3.4.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}
